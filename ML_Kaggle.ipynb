{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import geopy.distance\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.metrics import accuracy_score, f1_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data = pd.read_csv('/home/lakshikka/Desktop/Semester 07/ML/project/train.csv', \n",
    "                   parse_dates = ['pickup_time', 'drop_time']).drop(columns = 'tripid')\n",
    "df_test = pd.read_csv('/home/lakshikka/Desktop/Semester 07/ML/project/test.csv', \n",
    "                   parse_dates = ['pickup_time', 'drop_time']).drop(columns = 'tripid')\n",
    "\n",
    "# Remove na\n",
    "data = data.dropna()\n",
    "df_test = df_test.dropna()\n",
    "data.head()\n",
    "\n",
    "data['label'] = data['label'].map( {'incorrect':0, 'correct':1})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#data.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#creating new column for meter waiting rate\n",
    "data['meter_waiting_rate'] = data['meter_waiting_fare']/data['meter_waiting']\n",
    "data['meter_waiting_rate'] = data['meter_waiting_rate'].fillna(0.0)\n",
    "\n",
    "df_test['meter_waiting_rate'] = df_test['meter_waiting_fare']/df_test['meter_waiting']\n",
    "df_test['meter_waiting_rate'] = df_test['meter_waiting_rate'].fillna(0.0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Creating new columns for train and test data from pickup and drop time\n",
    "\n",
    "data['p_year'] = data.pickup_time.dt.year\n",
    "data['p_month'] = data.pickup_time.dt.month\n",
    "data['p_day'] = data.pickup_time.dt.day\n",
    "data['p_hour'] = data.pickup_time.dt.hour\n",
    "data['p_min'] = data.pickup_time.dt.minute\n",
    "data['p_weekday'] = data.pickup_time.dt.weekday_name\n",
    "\n",
    "\n",
    "data['d_year'] = data.drop_time.dt.year\n",
    "data['d_month'] = data.drop_time.dt.month\n",
    "data['d_day'] = data.drop_time.dt.day\n",
    "data['d_hour'] = data.drop_time.dt.hour\n",
    "data['d_min'] = data.drop_time.dt.minute\n",
    "data['d_weekday'] = data.drop_time.dt.weekday_name\n",
    "\n",
    "df_test['p_year'] = df_test.pickup_time.dt.year\n",
    "df_test['p_month'] = df_test.pickup_time.dt.month\n",
    "df_test['p_day'] = df_test.pickup_time.dt.day\n",
    "df_test['p_hour'] = df_test.pickup_time.dt.hour\n",
    "df_test['p_min'] = df_test.pickup_time.dt.minute\n",
    "df_test['p_weekday'] = df_test.pickup_time.dt.weekday_name\n",
    "\n",
    "df_test['d_year'] = df_test.drop_time.dt.year\n",
    "df_test['d_month'] = df_test.drop_time.dt.month\n",
    "df_test['d_day'] = df_test.drop_time.dt.day\n",
    "df_test['d_hour'] = df_test.drop_time.dt.hour\n",
    "df_test['d_min'] = df_test.drop_time.dt.minute\n",
    "df_test['d_weekday'] = df_test.drop_time.dt.weekday_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Distance calculation of the trip\n",
    "def distance(row):\n",
    "    return geopy.distance.distance((row.pick_lat, row.pick_lon),(row.drop_lat, row.drop_lon)).mi\n",
    "\n",
    "data['distance']= data.apply(lambda r: distance(r), axis=1)\n",
    "df_test['distance']= data.apply(lambda r: distance(r), axis=1)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Encoding categorical values for weekdays\n",
    "lb_make = LabelEncoder()\n",
    "\n",
    "data['p_weekday'] = lb_make.fit_transform(data['p_weekday'])\n",
    "data['d_weekday'] = lb_make.fit_transform(data['d_weekday'])\n",
    "\n",
    "df_test['p_weekday'] = lb_make.fit_transform(df_test['p_weekday'])\n",
    "df_test['d_weekday'] = lb_make.fit_transform(df_test['d_weekday'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "df_train = data[['additional_fare','duration', 'meter_waiting_rate', 'meter_waiting_till_pickup', 'pick_lat', 'pick_lon','drop_lat','drop_lon', 'fare', 'p_year' , 'p_month', 'p_day','p_hour','p_min','d_day','d_hour','d_min','distance', 'p_weekday','d_weekday' ]]\n",
    "df_label = data[['label']]\n",
    "\n",
    "#X_train_1, X_test_1, Y_train_1, Y_test_1 = train_test_split(df_train, df_train, test_size=0.2)\n",
    "df_test_sample = df_test[['additional_fare','duration', 'meter_waiting_rate', 'meter_waiting_till_pickup', 'pick_lat', 'pick_lon','drop_lat','drop_lon', 'fare', 'p_year' , 'p_month', 'p_day','p_hour','p_min','d_day','d_hour','d_min','distance' , 'p_weekday','d_weekday']]\n",
    "\n",
    "# Split our data\n",
    "train, test, train_labels, test_labels = train_test_split(df_train,\n",
    "                                                          df_label,\n",
    "                                                          test_size=0.33,\n",
    "                                                          random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from xgboost import XGBClassifier\n",
    "from sklearn.model_selection import RandomizedSearchCV, KFold\n",
    "from sklearn.metrics import f1_score\n",
    "\n",
    "clf_xgb = XGBClassifier(objective = 'binary:logistic')\n",
    "param_dist = { \"n_estimators\" :[100,200,500,1000],\n",
    "    \"learning_rate\"    : [0.05, 0.10, 0.15, 0.20, 0.25, 0.30 ] ,\n",
    " \"max_depth\"        : [ 3, 4, 5, 6, 8, 10, 12, 15],\n",
    " \"min_child_weight\" : [ 1, 3, 5, 7 ],\n",
    " \"gamma\"            : [ 0.0, 0.1, 0.2 , 0.3, 0.4 ],\n",
    " \"colsample_bytree\" : [ 0.3, 0.4, 0.5 , 0.7 ] }\n",
    "\n",
    "clf = RandomizedSearchCV(clf_xgb, param_distributions = param_dist, n_iter = 25, scoring = 'f1', error_score = 0, verbose = 3, n_jobs = -1)\n",
    "clf = clf.fit(train, train_labels)\n",
    "\n",
    "# Results from Random Search\n",
    "print(\"\\n========================================================\")\n",
    "print(\" Results from Random Search \" )\n",
    "print(\"========================================================\")\n",
    "print(\"\\n The best estimator across ALL searched params:\\n\",\n",
    "          clf.best_estimator_)\n",
    "print(\"\\n The best score across ALL searched params:\\n\",\n",
    "          clf.best_score_)\n",
    "print(\"\\n The best parameters across ALL searched params:\\n\",\n",
    "          clf.best_params_)\n",
    "print(\"\\n ========================================================\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import xgboost as xgb\n",
    "# xg_reg = xgb.XGBClassifier(objective ='binary:logistic',n_estimators = 1000,  learning_rate = 0.15, colsample_bytree=0.7,\n",
    "#                 max_depth = 6, gamma = 0.0, min_child_weight= 5)\n",
    "\n",
    "\n",
    "# xg_reg.fit(train, train_labels)\n",
    "# preds = xg_reg.predict(test)\n",
    "# print(f1_score(test_labels, preds, average=\"macro\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import xgboost as xgb\n",
    "xg_reg = xgb.XGBClassifier(objective ='binary:logistic',  learning_rate = 0.1, colsample_bytree=0.7,\n",
    "                max_depth = 12, gamma = 0.4, min_child_weight= 5)\n",
    "\n",
    "\n",
    "xg_reg.fit(df_train,df_label)\n",
    "Y_pred = xg_reg.predict(df_test_sample)\n",
    "#print(f1_score(test_labels, Y_pred, average=\"macro\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# submission_format = pd.read_csv('/home/lakshikka/Desktop/Semester 07/ML/project/sample_submission.csv', index_col='tripid')\n",
    "# my_submission = pd.DataFrame(data=Y_pred,\n",
    "#                              columns=submission_format.columns,\n",
    "#                              index=submission_format.index)\n",
    "# my_submission.to_csv('/home/lakshikka/Desktop/submission_Distance_04.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "(pd.Series(xg_reg.feature_importances_, index=train.columns)\n",
    "   .nlargest(30)\n",
    "   .plot(kind='barh'))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
